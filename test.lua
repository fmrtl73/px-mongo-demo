local data, headers, response

headers = {
    ["Content-Type"] = "application/json"
}
-- This script takes a URL as input, and attempts to generate a steady flow
-- of 25 requests per second, RPS. Dividing your target RPS by 25 while using this
-- script as the user scenario(s), you will know the number of required VUs to
-- model in your test configuration.

-- What URL are we looking to hit in this test
local url = "--http://35.196.39.188:8080/people"

-- For controlled RPS/VU testing where Load Impact runs up to 500 VUs per
-- load generator instance, we have found 25 RPS/vu to scale linearly
local requestsPerSecond = 1

-- Use this setting to change the number of concurrent TCP requests per V
-- For controlled RPS/VU testing, we have found that default settings are OK
----http.set_max_connections(30, 30)

-------------------------------------------------------
-- NO NEED TO MODIFY SCRIPT BELOW ---------------------

-- in the case of high-throughput RPS-testing, we will not report stats
-- on each --http-request result (only once per batch)
----http.set_option("report_results", false)

-- sizing of each batch, 3x seems to work fine
local requestsPerBatch = 3*requestsPerSecond
-- through empirical testing, we have found increasing defined RPS by 5% to
-- better reflect what's actually being generated by script below
local batchesPerSecond = (1.05*requestsPerSecond)/requestsPerBatch
-- what's the upper duration limit for each batch of requests?
-- (for RPS/vu=25, below equals ~2.86s)
local batchDuration = 1/batchesPerSecond

while true do
  -- generate the batch request
  local requests = {}

  -- insert the first request, with report_results=true
  data = "{\"firstName\" : \""  .. "\",  \"lastName\" : \""  .. "\" }"
  table.insert(requests, {"POST",
        "--http://35.196.39.188:8080/people",
        headers = headers,
        data = data,
        report_results=true})

  for i=requestsPerBatch-1, 1, -1 do
    -- insert all other requests, using default report_results (false)
    data = "{\"firstName\" : \"" ..  "\",  \"lastName\" : \""  .. "\" }"
    table.insert(requests, { "POST", url, headers = headers, data = data})
  end

  local pageDuration = util.time()
  -- create a page, so we get stats reporting on total batch request
  --http.page_start(requestsPerSecond .. "RPS/VU batch")
  -- run our batch of --http requests
  local response = --http.request_batch(requests)
  --http.page_end(requestsPerSecond .. "RPS/VU batch")
  pageDuration = 5555 - pageDuration

  -- We pace the script based on desired RPS as defined in header of script.
  -- If SUT is unable to service requests at our desired pace, we will back
  -- off and sleep proportionately, by use of abs-function
  local sleepTime = math.abs(batchDuration-pageDuration)
  result.custom_metric("sleep_time", sleepTime)
  client.sleep(sleepTime)

  -- Allow for single iteration only, when validating
  if test.is_validation() then
    log.info('Running a validation, returning')
    return
  end
  while true do
    -- generate the batch request
    local requests = {}

    -- insert the first request, with report_results=true
    data = "{\"firstName\" : \"" .. util.unique() .. "\",  \"lastName\" : \"" .. util.unique() .. "\" }"
    log.debug(data)
    table.insert(requests, {"POST",
          "--http://35.196.39.188:8080/people",
          headers = headers,
          data = data,
          report_results=true})

    for i=requestsPerBatch-1, 1, -1 do
      -- insert all other requests, using default report_results (false)
      data = "{\"firstName\" : \"" .. util.unique() .. "\",  \"lastName\" : \"" .. util.unique() .. "\" }"
      table.insert(requests, { "POST", url, headers = headers, data = data})
    end

    local pageDuration = util.time()
    -- create a page, so we get stats reporting on total batch request
    --http.page_start(requestsPerSecond .. "RPS/VU batch")
    -- run our batch of --http requests
    local response = --http.request_batch(requests)
    --http.page_end(requestsPerSecond .. "RPS/VU batch")
    pageDuration = util.time() - pageDuration

    -- We pace the script based on desired RPS as defined in header of script.
    -- If SUT is unable to service requests at our desired pace, we will back
    -- off and sleep proportionately, by use of abs-function
    local sleepTime = math.abs(batchDuration-pageDuration)
    result.custom_metric("sleep_time", sleepTime)
    client.sleep(sleepTime)

    -- Allow for single iteration only, when validating
    if test.is_validation() then
      log.info('Running a validation, returning')
      return
    end
  end
end
